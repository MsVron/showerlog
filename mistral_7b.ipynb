{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸ§  Mistral 7B Task Breakdown System for ShowerLog\n",
    "\n",
    "**Superior AI-powered task decomposition using Mistral-7B-Instruct-v0.2**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Environment Setup and Token Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import sys\n",
    "import torch\n",
    "import os\n",
    "\n",
    "print(\"Installing dependencies...\")\n",
    "subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \n",
    "               \"torch\", \"transformers\", \"accelerate\", \"bitsandbytes\", \n",
    "               \"flask\", \"flask-cors\", \"pyngrok\", \"sentencepiece\", \"psutil\", \"requests\"], check=True)\n",
    "\n",
    "print(f\"CUDA Available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB\")\n",
    "\n",
    "# ðŸ”‘ CRITICAL: Add your authentication tokens here!\n",
    "print(\"\\nðŸ”‘ Token Configuration Required:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# 1. Hugging Face Token (Required for Mistral model access)\n",
    "# Get your token from: https://huggingface.co/settings/tokens\n",
    "# You need 'Read' permission to access the Mistral model\n",
    "HUGGINGFACE_TOKEN = \"YOUR_HUGGINGFACE_TOKEN_HERE\"\n",
    "\n",
    "# 2. Ngrok Token (Required for public URL tunnel)\n",
    "# Get your token from: https://dashboard.ngrok.com/get-started/your-authtoken\n",
    "# Free accounts get 1 tunnel, which is perfect for this project\n",
    "NGROK_TOKEN = \"YOUR_NGROK_TOKEN_HERE\"\n",
    "\n",
    "# Token validation and setup\n",
    "if HUGGINGFACE_TOKEN == \"YOUR_HUGGINGFACE_TOKEN_HERE\":\n",
    "    print(\"âŒ MISSING: Hugging Face Token\")\n",
    "    print(\"ðŸ“ Steps to get your token:\")\n",
    "    print(\"   1. Go to: https://huggingface.co/settings/tokens\")\n",
    "    print(\"   2. Click 'New token'\")\n",
    "    print(\"   3. Name it 'showerlog-mistral'\")\n",
    "    print(\"   4. Select 'Read' permission\")\n",
    "    print(\"   5. Copy the token and paste it above\")\n",
    "    print(\"   6. Replace 'YOUR_HUGGINGFACE_TOKEN_HERE' with your actual token\")\n",
    "    print(\"   Example: hf_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\")\n",
    "    raise ValueError(\"âŒ Hugging Face token required for Mistral model access!\")\n",
    "\n",
    "if NGROK_TOKEN == \"YOUR_NGROK_TOKEN_HERE\":\n",
    "    print(\"âŒ MISSING: Ngrok Token\")\n",
    "    print(\"ðŸ“ Steps to get your token:\")\n",
    "    print(\"   1. Go to: https://dashboard.ngrok.com/get-started/your-authtoken\")\n",
    "    print(\"   2. Sign up for free if you don't have an account\")\n",
    "    print(\"   3. Copy your authtoken from the dashboard\")\n",
    "    print(\"   4. Replace 'YOUR_NGROK_TOKEN_HERE' with your actual token\")\n",
    "    print(\"   Example: 2abcdefghijk1234567890mnopqrstuvwxyz_abcdefghijklmnopqrstuvwxyz123\")\n",
    "    raise ValueError(\"âŒ Ngrok token required for public URL access!\")\n",
    "\n",
    "# Set environment variables for authentication\n",
    "os.environ['HUGGINGFACE_HUB_TOKEN'] = HUGGINGFACE_TOKEN\n",
    "os.environ['HF_TOKEN'] = HUGGINGFACE_TOKEN\n",
    "\n",
    "# Set up ngrok authentication\n",
    "from pyngrok import ngrok\n",
    "ngrok.set_auth_token(NGROK_TOKEN)\n",
    "\n",
    "print(\"âœ… Environment setup complete!\")\n",
    "print(\"âœ… Hugging Face token configured\")\n",
    "print(\"âœ… Ngrok token configured\")\n",
    "print(\"ðŸš€ Ready to load Mistral 7B model!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import warnings\n",
    "import psutil\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "model_id = \"mistralai/Mistral-7B-Instruct-v0.2\"\n",
    "\n",
    "# Check available memory and hardware\n",
    "print(f\"Available RAM: {psutil.virtual_memory().available / (1024**3):.1f} GB\")\n",
    "print(f\"CUDA Available: {torch.cuda.is_available()}\")\n",
    "\n",
    "# Load tokenizer first\n",
    "print(\"ðŸ”„ Loading tokenizer...\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "print(\"âœ… Tokenizer loaded successfully!\")\n",
    "\n",
    "# Smart model loading strategy for Kaggle environment\n",
    "print(\"ðŸ”„ Loading model with Kaggle-optimized configuration...\")\n",
    "\n",
    "try:\n",
    "    # Method 1: Try GPU loading without quantization (works better in Kaggle)\n",
    "    if torch.cuda.is_available():\n",
    "        print(\"ðŸš€ Attempting GPU loading without quantization...\")\n",
    "        model = AutoModelForCausalLM.from_pretrained(\n",
    "            model_id,\n",
    "            device_map=\"auto\",\n",
    "            trust_remote_code=True,\n",
    "            torch_dtype=torch.float16,\n",
    "            low_cpu_mem_usage=True\n",
    "        )\n",
    "        print(\"âœ… Mistral 7B loaded successfully on GPU!\")\n",
    "    else:\n",
    "        raise Exception(\"CUDA not available, falling back to CPU\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"âš ï¸ GPU loading failed: {str(e)}\")\n",
    "    print(\"ðŸ”„ Trying CPU loading with optimizations...\")\n",
    "    \n",
    "    try:\n",
    "        # Method 2: CPU loading with memory optimizations\n",
    "        model = AutoModelForCausalLM.from_pretrained(\n",
    "            model_id,\n",
    "            device_map=\"cpu\",\n",
    "            trust_remote_code=True,\n",
    "            torch_dtype=torch.float32,\n",
    "            low_cpu_mem_usage=True\n",
    "        )\n",
    "        print(\"âœ… Mistral 7B loaded successfully on CPU!\")\n",
    "        \n",
    "    except Exception as e2:\n",
    "        print(f\"âš ï¸ CPU loading failed: {str(e2)}\")\n",
    "        print(\"ðŸ”„ Trying minimal loading configuration...\")\n",
    "        \n",
    "        # Method 3: Last resort - minimal configuration\n",
    "        model = AutoModelForCausalLM.from_pretrained(\n",
    "            model_id,\n",
    "            trust_remote_code=True,\n",
    "            low_cpu_mem_usage=True\n",
    "        )\n",
    "        print(\"âœ… Mistral 7B loaded with minimal configuration!\")\n",
    "\n",
    "print(f\"ðŸ“ Model device: {next(model.parameters()).device}\")\n",
    "print(f\"ðŸ“Š Model memory footprint: ~{sum(p.numel() * p.element_size() for p in model.parameters()) / (1024**3):.1f} GB\")\n",
    "print(\"ðŸŽ¯ Ready for intelligent task breakdown generation!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Advanced Infinite Task Breakdown AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ§  Initializing Mistral Infinite Task Breakdown AI...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 634\u001b[0m\n\u001b[0;32m    632\u001b[0m \u001b[38;5;66;03m# Initialize Enhanced AI system\u001b[39;00m\n\u001b[0;32m    633\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mðŸ§  Initializing Mistral Infinite Task Breakdown AI...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 634\u001b[0m task_ai \u001b[38;5;241m=\u001b[39m MistralInfiniteTaskBreakdownAI(\u001b[43mmodel\u001b[49m, tokenizer)\n\u001b[0;32m    635\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mâœ… Advanced AI system ready for infinite task breakdown!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import re\n",
    "import time\n",
    "from typing import Dict, Any, List\n",
    "\n",
    "class MistralInfiniteTaskBreakdownAI:\n",
    "    def __init__(self, model, tokenizer):\n",
    "        self.model = model\n",
    "        self.tokenizer = tokenizer\n",
    "        # Fast generation config optimized for Kaggle\n",
    "        self.generation_config = {\n",
    "            \"max_new_tokens\": 500,  # Reduced for faster generation\n",
    "            \"temperature\": 0.3,     # Lower for more focused output\n",
    "            \"top_p\": 0.85,         # Slightly more focused\n",
    "            \"do_sample\": True,\n",
    "            \"pad_token_id\": tokenizer.eos_token_id,\n",
    "            \"early_stopping\": True, # Stop early when EOS is generated\n",
    "            \"num_beams\": 1,        # No beam search for speed\n",
    "        }\n",
    "        self.complexity_weights = {\n",
    "            'simple': 0.3,\n",
    "            'moderate': 0.6,\n",
    "            'complex': 0.8,\n",
    "            'enterprise': 1.0\n",
    "        }\n",
    "        self.project_contexts = {\n",
    "            # Technology & Development\n",
    "            'software': 'software development, coding, technical implementation, programming, system architecture',\n",
    "            'web': 'web development, frontend, backend, full-stack, responsive design, user experience',\n",
    "            'mobile': 'mobile app development, iOS, Android, cross-platform, React Native, Flutter',\n",
    "            'ai': 'artificial intelligence, machine learning, data science, neural networks, automation',\n",
    "            'cybersecurity': 'information security, penetration testing, vulnerability assessment, compliance',\n",
    "            'devops': 'deployment, CI/CD, infrastructure, cloud computing, containerization, monitoring',\n",
    "            \n",
    "            # Business & Finance\n",
    "            'business': 'business strategy, market analysis, financial planning, operations, growth',\n",
    "            'startup': 'startup development, MVP creation, fundraising, pitch decks, market validation',\n",
    "            'finance': 'financial management, budgeting, investment, accounting, tax planning, wealth building',\n",
    "            'marketing': 'digital marketing, SEO, social media, content marketing, brand building, campaigns',\n",
    "            'sales': 'sales strategy, lead generation, customer acquisition, CRM, sales funnels',\n",
    "            'consulting': 'business consulting, strategic advice, process optimization, change management',\n",
    "            'ecommerce': 'online retail, marketplace development, inventory management, customer service',\n",
    "            \n",
    "            # Creative & Arts\n",
    "            'creative': 'artistic creation, design, content development, visual arts, creative expression',\n",
    "            'design': 'graphic design, UI/UX design, product design, branding, typography, visual identity',\n",
    "            'photography': 'photography techniques, photo editing, portfolio building, commercial photography',\n",
    "            'videography': 'video production, filming, editing, cinematography, storytelling, post-production',\n",
    "            'music': 'music composition, recording, mixing, mastering, live performance, music business',\n",
    "            'writing': 'creative writing, copywriting, blogging, journalism, storytelling, publishing',\n",
    "            'art': 'fine arts, painting, drawing, sculpture, digital art, art history, gallery management',\n",
    "            'fashion': 'fashion design, styling, trend analysis, fashion business, sustainable fashion',\n",
    "            \n",
    "            # Health & Wellness\n",
    "            'fitness': 'physical fitness, workout planning, strength training, cardio, nutrition, wellness',\n",
    "            'nutrition': 'meal planning, diet optimization, healthy eating, weight management, supplements',\n",
    "            'mental_health': 'stress management, mindfulness, meditation, therapy, emotional wellness',\n",
    "            'healthcare': 'medical practice, patient care, healthcare administration, medical research',\n",
    "            'beauty': 'skincare, makeup, beauty treatments, cosmetics, personal grooming, beauty business',\n",
    "            'wellness': 'holistic health, lifestyle optimization, work-life balance, self-care practices',\n",
    "            \n",
    "            # Education & Learning\n",
    "            'learning': 'education, skill development, knowledge acquisition, study techniques, certification',\n",
    "            'teaching': 'curriculum development, lesson planning, educational methods, student engagement',\n",
    "            'research': 'academic research, data collection, analysis, thesis writing, scientific method',\n",
    "            'language': 'language learning, linguistics, translation, communication skills, cultural studies',\n",
    "            'academics': 'academic planning, degree completion, scholarship applications, academic writing',\n",
    "            \n",
    "            # Sports & Recreation\n",
    "            'sports': 'athletic training, sports performance, coaching, team management, sports medicine',\n",
    "            'outdoor': 'outdoor activities, hiking, camping, adventure sports, nature exploration',\n",
    "            'gaming': 'game development, esports, gaming content creation, competitive gaming',\n",
    "            'hobby': 'hobby development, crafts, collecting, recreational activities, personal interests',\n",
    "            'travel': 'travel planning, itinerary creation, budget travel, cultural exploration, tourism',\n",
    "            \n",
    "            # Performing Arts & Entertainment\n",
    "            'dancing': 'dance training, choreography, performance preparation, dance styles, dance business',\n",
    "            'theater': 'acting, theater production, stage management, script writing, performance arts',\n",
    "            'entertainment': 'event planning, entertainment industry, content creation, media production',\n",
    "            'comedy': 'comedy writing, stand-up performance, humor development, entertainment content',\n",
    "            \n",
    "            # Personal Development & Relationships\n",
    "            'relationships': 'relationship building, communication skills, dating, marriage, family dynamics',\n",
    "            'personal': 'personal development, goal setting, habit formation, life coaching, self-improvement',\n",
    "            'social': 'social skills, networking, community building, social media presence, influence',\n",
    "            'parenting': 'child development, parenting strategies, education planning, family management',\n",
    "            'dating': 'dating strategies, relationship building, social confidence, romantic connections',\n",
    "            \n",
    "            # Home & Lifestyle\n",
    "            'cooking': 'culinary skills, recipe development, meal preparation, food safety, cooking techniques',\n",
    "            'gardening': 'plant care, garden design, sustainable gardening, urban farming, landscaping',\n",
    "            'diy': 'do-it-yourself projects, home improvement, crafts, repairs, building, woodworking',\n",
    "            'home': 'home organization, interior design, cleaning, maintenance, home automation',\n",
    "            'sustainability': 'eco-friendly living, renewable energy, waste reduction, sustainable practices',\n",
    "            \n",
    "            # Career & Professional\n",
    "            'career': 'career development, job searching, professional growth, skill building, networking',\n",
    "            'job_hunting': 'resume writing, interview preparation, job applications, career transitions',\n",
    "            'freelancing': 'freelance business, client acquisition, project management, independent work',\n",
    "            'leadership': 'leadership development, team management, organizational skills, executive coaching',\n",
    "            'productivity': 'time management, efficiency optimization, workflow improvement, productivity systems',\n",
    "            \n",
    "            # Science & Technology\n",
    "            'science': 'scientific research, experimentation, data analysis, laboratory work, innovation',\n",
    "            'engineering': 'engineering design, problem solving, technical analysis, system optimization',\n",
    "            'environment': 'environmental science, conservation, climate action, sustainability projects',\n",
    "            'astronomy': 'space science, astronomy observation, astrophotography, space exploration',\n",
    "            \n",
    "            # Manufacturing & Trades\n",
    "            'manufacturing': 'production processes, quality control, supply chain, industrial engineering',\n",
    "            'construction': 'building projects, renovation, architecture, project management, safety',\n",
    "            'automotive': 'vehicle maintenance, automotive repair, car restoration, automotive business',\n",
    "            'crafts': 'handmade crafts, artisan skills, craft business, traditional techniques',\n",
    "            \n",
    "            # Agriculture & Food\n",
    "            'agriculture': 'farming, crop management, livestock, agricultural technology, sustainable farming',\n",
    "            'food': 'food production, food safety, culinary business, restaurant management, food science',\n",
    "            \n",
    "            # Non-Profit & Social Impact\n",
    "            'nonprofit': 'nonprofit management, fundraising, volunteer coordination, social impact, community service',\n",
    "            'volunteer': 'volunteer work, community service, social causes, charitable activities',\n",
    "            'activism': 'social activism, campaign organizing, advocacy, community organizing, change-making',\n",
    "            \n",
    "            # Real Estate & Property\n",
    "            'realestate': 'property investment, real estate business, property management, home buying',\n",
    "            'property': 'property development, real estate marketing, property maintenance, investment',\n",
    "            \n",
    "            # Legal & Compliance\n",
    "            'legal': 'legal research, compliance, contract management, legal documentation, law practice',\n",
    "            \n",
    "            # Transportation & Logistics\n",
    "            'logistics': 'supply chain management, transportation, inventory, distribution, operations',\n",
    "            'transportation': 'vehicle operation, route planning, transportation business, mobility solutions',\n",
    "            \n",
    "            # Default\n",
    "            'general': 'project management, goal achievement, systematic approach, strategic planning, execution'\n",
    "        }\n",
    "    \n",
    "    def create_smart_prompt(self, thought: str, project_type: str = 'general', complexity: str = 'moderate') -> str:\n",
    "        context = self.project_contexts.get(project_type, self.project_contexts['general'])\n",
    "        complexity_factor = self.complexity_weights.get(complexity, 0.6)\n",
    "        \n",
    "        return f\"\"\"<s>[INST] You are an expert project manager and task breakdown specialist with deep expertise in {context}. \n",
    "\n",
    "Analyze this project idea: \"{thought}\"\n",
    "\n",
    "Project Context: {project_type.title()} project with {complexity} complexity level\n",
    "Your task: Create an intelligent, comprehensive task breakdown that maximizes the chances of successful project completion.\n",
    "\n",
    "Requirements:\n",
    "1. **Strategic Analysis**: Consider the project's scope, dependencies, risks, and success factors\n",
    "2. **Adaptive Complexity**: Adjust task granularity based on complexity level ({complexity})\n",
    "3. **Domain Expertise**: Apply {project_type} best practices and methodologies\n",
    "4. **Realistic Planning**: Provide accurate time estimates and difficulty assessments\n",
    "\n",
    "Generate:\n",
    "- Clear, measurable main goal\n",
    "- Appropriate category classification  \n",
    "- Priority level based on impact and urgency\n",
    "- 5-8 strategically sequenced subtasks\n",
    "- Project complexity score (1-10)\n",
    "- Total estimated hours\n",
    "- Project type classification\n",
    "\n",
    "For each subtask provide:\n",
    "- **Specific, actionable title** (avoid generic terms)\n",
    "- **Detailed implementation description** \n",
    "- **Realistic time estimate** (hours/days/weeks)\n",
    "- **Accurate difficulty level** (easy/medium/hard)\n",
    "- **Dependencies and prerequisites**\n",
    "\n",
    "Respond ONLY with this JSON structure:\n",
    "{{\n",
    "  \"main_goal\": \"Specific, measurable goal description\",\n",
    "  \"category\": \"app|business|learning|creative|lifestyle|health|productivity|other\",\n",
    "  \"priority\": \"high|medium|low\",\n",
    "  \"project_type\": \"{project_type}\",\n",
    "  \"complexity_score\": 1-10,\n",
    "  \"total_estimated_hours\": total_hours_number,\n",
    "  \"subtasks\": [\n",
    "    {{\n",
    "      \"id\": 1,\n",
    "      \"title\": \"Specific actionable task title\",\n",
    "      \"description\": \"Detailed step-by-step implementation guide\",\n",
    "      \"estimated_time\": \"X hours|days|weeks\",\n",
    "      \"difficulty\": \"easy|medium|hard\"\n",
    "    }}\n",
    "  ]\n",
    "}}[/INST]\"\"\"\n",
    "\n",
    "    def create_nested_prompt(self, parent_task: Dict, context: str, depth: int) -> str:\n",
    "        return f\"\"\"<s>[INST] You are an expert task breakdown specialist. Break down this specific task into smaller, actionable subtasks.\n",
    "\n",
    "Parent Task: \"{parent_task['title']}\"\n",
    "Description: \"{parent_task['description']}\"\n",
    "Difficulty: {parent_task['difficulty']}\n",
    "Time Estimate: {parent_task['estimated_time']}\n",
    "\n",
    "Project Context: {context}\n",
    "Current Breakdown Depth: Level {depth}\n",
    "\n",
    "Your expertise: Analyze this task and determine if it can be broken down into smaller, more manageable subtasks. Consider:\n",
    "- Task complexity and scope\n",
    "- Natural workflow and dependencies  \n",
    "- Skill requirements and knowledge areas\n",
    "- Time management and efficiency\n",
    "- Quality checkpoints and milestones\n",
    "\n",
    "If this task is complex enough to warrant breakdown (typically tasks >2 hours or medium/hard difficulty), create 3-6 specific subtasks.\n",
    "If it's already sufficiently granular, return empty subtasks array.\n",
    "\n",
    "IMPORTANT: Only break down tasks that genuinely benefit from subdivision. Don't create unnecessary micro-tasks.\n",
    "\n",
    "Respond ONLY with JSON:\n",
    "{{\n",
    "  \"subtasks\": [\n",
    "    {{\n",
    "      \"id\": 1,\n",
    "      \"title\": \"Specific sub-task title\",\n",
    "      \"description\": \"Detailed implementation steps\",\n",
    "      \"estimated_time\": \"X hours|days\",\n",
    "      \"difficulty\": \"easy|medium|hard\"\n",
    "    }}\n",
    "  ],\n",
    "  \"breakdown_reasoning\": \"Brief explanation of why these subtasks improve the workflow\",\n",
    "  \"depth_level\": {depth}\n",
    "}}\n",
    "\n",
    "If no breakdown is needed, respond with:\n",
    "{{\n",
    "  \"subtasks\": [],\n",
    "  \"breakdown_reasoning\": \"Task is already sufficiently granular\",\n",
    "  \"depth_level\": {depth}\n",
    "}}[/INST]\"\"\"\n",
    "\n",
    "    def generate_smart_breakdown(self, thought: str, project_type: str = 'general', complexity: str = 'moderate') -> Dict[str, Any]:\n",
    "        start_time = time.time()\n",
    "        \n",
    "        try:\n",
    "            prompt = self.create_smart_prompt(thought, project_type, complexity)\n",
    "            inputs = self.tokenizer(prompt, return_tensors=\"pt\", truncation=True, max_length=2500)\n",
    "            inputs = {k: v.to(self.model.device) for k, v in inputs.items()}\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                outputs = self.model.generate(**inputs, **self.generation_config)\n",
    "            \n",
    "            generated_ids = outputs[0][len(inputs[\"input_ids\"][0]):]\n",
    "            response = self.tokenizer.decode(generated_ids, skip_special_tokens=True)\n",
    "            \n",
    "            parsed_result = self.parse_smart_response(response, thought, project_type, complexity)\n",
    "            processing_time = time.time() - start_time\n",
    "            \n",
    "            return {\n",
    "                \"success\": True,\n",
    "                \"data\": parsed_result,\n",
    "                \"processing_time\": f\"{processing_time:.2f}s\",\n",
    "                \"model_response\": response[:300] + \"...\" if len(response) > 300 else response\n",
    "            }\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Smart breakdown error: {str(e)}\")\n",
    "            return {\n",
    "                \"success\": False,\n",
    "                \"error\": str(e),\n",
    "                \"data\": self.create_intelligent_fallback(thought, project_type, complexity)\n",
    "            }\n",
    "    \n",
    "    def generate_nested_breakdown(self, parent_task: Dict, context: str, depth: int) -> Dict[str, Any]:\n",
    "        start_time = time.time()\n",
    "        \n",
    "        try:\n",
    "            if depth >= 5:\n",
    "                return {\n",
    "                    \"success\": False,\n",
    "                    \"error\": \"Maximum breakdown depth reached\",\n",
    "                    \"subtasks\": []\n",
    "                }\n",
    "            \n",
    "            prompt = self.create_nested_prompt(parent_task, context, depth)\n",
    "            inputs = self.tokenizer(prompt, return_tensors=\"pt\", truncation=True, max_length=2000)\n",
    "            inputs = {k: v.to(self.model.device) for k, v in inputs.items()}\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                outputs = self.model.generate(**inputs, **self.generation_config)\n",
    "            \n",
    "            generated_ids = outputs[0][len(inputs[\"input_ids\"][0]):]\n",
    "            response = self.tokenizer.decode(generated_ids, skip_special_tokens=True)\n",
    "            \n",
    "            parsed_result = self.parse_nested_response(response, depth)\n",
    "            processing_time = time.time() - start_time\n",
    "            \n",
    "            return {\n",
    "                \"success\": True,\n",
    "                \"subtasks\": parsed_result.get(\"subtasks\", []),\n",
    "                \"breakdown_reasoning\": parsed_result.get(\"breakdown_reasoning\", \"\"),\n",
    "                \"depth_level\": depth,\n",
    "                \"processing_time\": f\"{processing_time:.2f}s\",\n",
    "                \"timestamp\": time.time()\n",
    "            }\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Nested breakdown error: {str(e)}\")\n",
    "            return {\n",
    "                \"success\": False,\n",
    "                \"error\": str(e),\n",
    "                \"subtasks\": [],\n",
    "                \"depth_level\": depth\n",
    "            }\n",
    "    \n",
    "    def parse_response(self, response: str, thought: str) -> Dict[str, Any]:\n",
    "        try:\n",
    "            start_idx = response.find('{')\n",
    "            end_idx = response.rfind('}') + 1\n",
    "            \n",
    "            if start_idx == -1 or end_idx == 0:\n",
    "                raise ValueError(\"No JSON found\")\n",
    "            \n",
    "            json_str = response[start_idx:end_idx]\n",
    "            parsed = json.loads(json_str)\n",
    "            \n",
    "            return self.validate_response(parsed, thought)\n",
    "            \n",
    "        except Exception:\n",
    "            return self.create_fallback(thought)\n",
    "    \n",
    "    def validate_response(self, data: Dict[str, Any], thought: str) -> Dict[str, Any]:\n",
    "        if \"main_goal\" not in data:\n",
    "            data[\"main_goal\"] = f\"Complete project: {thought}\"\n",
    "        \n",
    "        valid_categories = [\"app\", \"business\", \"learning\", \"creative\", \"lifestyle\", \"health\", \"productivity\", \"other\"]\n",
    "        if \"category\" not in data or data[\"category\"] not in valid_categories:\n",
    "            data[\"category\"] = \"other\"\n",
    "        \n",
    "        if \"priority\" not in data or data[\"priority\"] not in [\"high\", \"medium\", \"low\"]:\n",
    "            data[\"priority\"] = \"medium\"\n",
    "        \n",
    "        if \"subtasks\" not in data or not isinstance(data[\"subtasks\"], list):\n",
    "            return self.create_fallback(thought)\n",
    "        \n",
    "        cleaned_subtasks = []\n",
    "        for i, task in enumerate(data[\"subtasks\"][:7], 1):\n",
    "            cleaned_task = {\n",
    "                \"id\": i,\n",
    "                \"title\": str(task.get(\"title\", f\"Task {i}\")).strip(),\n",
    "                \"description\": str(task.get(\"description\", \"Complete this task\")).strip(),\n",
    "                \"estimated_time\": self.normalize_time(task.get(\"estimated_time\", \"2 hours\")),\n",
    "                \"difficulty\": task.get(\"difficulty\", \"medium\") if task.get(\"difficulty\") in [\"easy\", \"medium\", \"hard\"] else \"medium\"\n",
    "            }\n",
    "            cleaned_subtasks.append(cleaned_task)\n",
    "        \n",
    "        data[\"subtasks\"] = cleaned_subtasks\n",
    "        return data\n",
    "    \n",
    "    def normalize_time(self, time_str: str) -> str:\n",
    "        time_str = str(time_str).lower().strip()\n",
    "        \n",
    "        if any(word in time_str for word in [\"30\", \"45\", \"1 hour\", \"1hr\"]):\n",
    "            return \"1 hour\"\n",
    "        elif any(word in time_str for word in [\"2\", \"couple\"]):\n",
    "            return \"2 hours\"\n",
    "        elif any(word in time_str for word in [\"3\", \"few\"]):\n",
    "            return \"3 hours\"\n",
    "        elif any(word in time_str for word in [\"4\", \"half day\"]):\n",
    "            return \"4 hours\"\n",
    "        elif any(word in time_str for word in [\"day\", \"8 hours\"]):\n",
    "            return \"1 day\"\n",
    "        elif any(word in time_str for word in [\"week\"]):\n",
    "            return \"1 week\"\n",
    "        else:\n",
    "            return time_str if time_str else \"2 hours\"\n",
    "    \n",
    "    def create_fallback(self, thought: str) -> Dict[str, Any]:\n",
    "        thought_lower = thought.lower()\n",
    "        \n",
    "        if any(word in thought_lower for word in [\"app\", \"website\", \"software\", \"code\"]):\n",
    "            category = \"app\"\n",
    "            tasks = [\n",
    "                (\"Project Planning & Requirements\", \"Define scope, features, and technical requirements\", \"3 hours\", \"medium\"),\n",
    "                (\"Technology Stack Selection\", \"Choose frameworks, databases, and development tools\", \"2 hours\", \"easy\"),\n",
    "                (\"UI/UX Design & Wireframes\", \"Create user interface mockups and user flows\", \"6 hours\", \"medium\"),\n",
    "                (\"Development Environment Setup\", \"Set up dev tools, version control, and project structure\", \"2 hours\", \"easy\"),\n",
    "                (\"Core Feature Implementation\", \"Build main functionality and user interface\", \"12 hours\", \"hard\"),\n",
    "                (\"Testing & Quality Assurance\", \"Test features, fix bugs, ensure reliability\", \"4 hours\", \"medium\")\n",
    "            ]\n",
    "        elif any(word in thought_lower for word in [\"business\", \"startup\", \"company\"]):\n",
    "            category = \"business\"\n",
    "            tasks = [\n",
    "                (\"Market Research & Validation\", \"Research target market and validate demand\", \"8 hours\", \"medium\"),\n",
    "                (\"Business Plan Development\", \"Create comprehensive plan with financials\", \"12 hours\", \"hard\"),\n",
    "                (\"Legal Structure & Registration\", \"Handle business registration and legal setup\", \"4 hours\", \"medium\"),\n",
    "                (\"Brand Identity & Marketing\", \"Develop brand, logo, and marketing strategy\", \"8 hours\", \"medium\"),\n",
    "                (\"Product/Service Development\", \"Build minimum viable product or service\", \"20 hours\", \"hard\"),\n",
    "                (\"Customer Acquisition Strategy\", \"Plan and implement customer acquisition\", \"6 hours\", \"medium\")\n",
    "            ]\n",
    "        elif any(word in thought_lower for word in [\"learn\", \"study\", \"skill\"]):\n",
    "            category = \"learning\"\n",
    "            tasks = [\n",
    "                (\"Learning Goal Definition\", \"Define specific objectives and success metrics\", \"1 hour\", \"easy\"),\n",
    "                (\"Resource Research\", \"Find quality learning materials and courses\", \"3 hours\", \"easy\"),\n",
    "                (\"Study Schedule Creation\", \"Create realistic schedule with milestones\", \"2 hours\", \"easy\"),\n",
    "                (\"Active Learning & Practice\", \"Engage with material through practice\", \"20 hours\", \"medium\"),\n",
    "                (\"Project Application\", \"Apply skills in real project\", \"8 hours\", \"hard\"),\n",
    "                (\"Knowledge Assessment\", \"Test understanding and identify gaps\", \"2 hours\", \"medium\")\n",
    "            ]\n",
    "        else:\n",
    "            category = \"other\"\n",
    "            tasks = [\n",
    "                (\"Research & Information Gathering\", \"Collect relevant information and understand requirements\", \"3 hours\", \"easy\"),\n",
    "                (\"Planning & Strategy\", \"Create detailed plan with timeline\", \"4 hours\", \"medium\"),\n",
    "                (\"Resource Acquisition\", \"Gather tools, materials, permissions\", \"2 hours\", \"easy\"),\n",
    "                (\"Initial Implementation\", \"Begin main work execution\", \"8 hours\", \"medium\"),\n",
    "                (\"Iteration & Refinement\", \"Review progress and improve\", \"4 hours\", \"medium\"),\n",
    "                (\"Completion & Documentation\", \"Finish and document results\", \"3 hours\", \"easy\")\n",
    "            ]\n",
    "        \n",
    "        subtasks = []\n",
    "        for i, (title, desc, time, diff) in enumerate(tasks[:6], 1):\n",
    "            subtasks.append({\n",
    "                \"id\": i,\n",
    "                \"title\": title,\n",
    "                \"description\": desc,\n",
    "                \"estimated_time\": time,\n",
    "                \"difficulty\": diff\n",
    "            })\n",
    "        \n",
    "        return {\n",
    "            \"main_goal\": f\"Successfully execute: {thought}\",\n",
    "            \"category\": category,\n",
    "            \"priority\": \"medium\",\n",
    "            \"subtasks\": subtasks\n",
    "        }\n",
    "    \n",
    "    def parse_smart_response(self, response: str, thought: str, project_type: str, complexity: str) -> Dict[str, Any]:\n",
    "        try:\n",
    "            start_idx = response.find('{')\n",
    "            end_idx = response.rfind('}') + 1\n",
    "            \n",
    "            if start_idx == -1 or end_idx == 0:\n",
    "                raise ValueError(\"No JSON found\")\n",
    "            \n",
    "            json_str = response[start_idx:end_idx]\n",
    "            parsed = json.loads(json_str)\n",
    "            \n",
    "            return self.validate_smart_response(parsed, thought, project_type, complexity)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Smart parsing error: {e}\")\n",
    "            return self.create_intelligent_fallback(thought, project_type, complexity)\n",
    "    \n",
    "    def parse_nested_response(self, response: str, depth: int) -> Dict[str, Any]:\n",
    "        try:\n",
    "            start_idx = response.find('{')\n",
    "            end_idx = response.rfind('}') + 1\n",
    "            \n",
    "            if start_idx == -1 or end_idx == 0:\n",
    "                raise ValueError(\"No JSON found\")\n",
    "            \n",
    "            json_str = response[start_idx:end_idx]\n",
    "            parsed = json.loads(json_str)\n",
    "            \n",
    "            if \"subtasks\" not in parsed:\n",
    "                parsed[\"subtasks\"] = []\n",
    "            \n",
    "            # Clean and validate subtasks\n",
    "            cleaned_subtasks = []\n",
    "            for i, task in enumerate(parsed[\"subtasks\"][:6], 1):\n",
    "                if isinstance(task, dict) and \"title\" in task:\n",
    "                    cleaned_task = {\n",
    "                        \"id\": i,\n",
    "                        \"title\": str(task.get(\"title\", f\"Subtask {i}\")).strip(),\n",
    "                        \"description\": str(task.get(\"description\", \"Complete this subtask\")).strip(),\n",
    "                        \"estimated_time\": self.normalize_time(task.get(\"estimated_time\", \"1 hour\")),\n",
    "                        \"difficulty\": task.get(\"difficulty\", \"easy\") if task.get(\"difficulty\") in [\"easy\", \"medium\", \"hard\"] else \"easy\"\n",
    "                    }\n",
    "                    cleaned_subtasks.append(cleaned_task)\n",
    "            \n",
    "            return {\n",
    "                \"subtasks\": cleaned_subtasks,\n",
    "                \"breakdown_reasoning\": parsed.get(\"breakdown_reasoning\", \"Task breakdown completed\"),\n",
    "                \"depth_level\": depth\n",
    "            }\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Nested parsing error: {e}\")\n",
    "            return {\n",
    "                \"subtasks\": [],\n",
    "                \"breakdown_reasoning\": \"Parsing failed, no subtasks generated\",\n",
    "                \"depth_level\": depth\n",
    "            }\n",
    "    \n",
    "    def validate_smart_response(self, data: Dict[str, Any], thought: str, project_type: str, complexity: str) -> Dict[str, Any]:\n",
    "        # Ensure required fields with intelligent defaults\n",
    "        if \"main_goal\" not in data:\n",
    "            data[\"main_goal\"] = f\"Successfully complete {project_type} project: {thought}\"\n",
    "        \n",
    "        valid_categories = [\"app\", \"business\", \"learning\", \"creative\", \"lifestyle\", \"health\", \"productivity\", \"other\"]\n",
    "        if \"category\" not in data or data[\"category\"] not in valid_categories:\n",
    "            data[\"category\"] = project_type if project_type in valid_categories else \"other\"\n",
    "        \n",
    "        if \"priority\" not in data or data[\"priority\"] not in [\"high\", \"medium\", \"low\"]:\n",
    "            data[\"priority\"] = \"high\" if complexity in [\"complex\", \"enterprise\"] else \"medium\"\n",
    "        \n",
    "        # Add missing advanced fields\n",
    "        if \"project_type\" not in data:\n",
    "            data[\"project_type\"] = project_type\n",
    "        \n",
    "        if \"complexity_score\" not in data:\n",
    "            complexity_scores = {\"simple\": 3, \"moderate\": 5, \"complex\": 7, \"enterprise\": 9}\n",
    "            data[\"complexity_score\"] = complexity_scores.get(complexity, 5)\n",
    "        \n",
    "        if \"total_estimated_hours\" not in data:\n",
    "            data[\"total_estimated_hours\"] = self.calculate_total_time(data.get(\"subtasks\", []))\n",
    "        \n",
    "        if \"subtasks\" not in data or not isinstance(data[\"subtasks\"], list):\n",
    "            return self.create_intelligent_fallback(thought, project_type, complexity)\n",
    "        \n",
    "        # Enhanced subtask processing\n",
    "        cleaned_subtasks = []\n",
    "        for i, task in enumerate(data[\"subtasks\"][:8], 1):  # Allow up to 8 tasks for complex projects\n",
    "            cleaned_task = {\n",
    "                \"id\": i,\n",
    "                \"title\": str(task.get(\"title\", f\"Task {i}\")).strip(),\n",
    "                \"description\": str(task.get(\"description\", \"Complete this task\")).strip(),\n",
    "                \"estimated_time\": self.normalize_time(task.get(\"estimated_time\", \"2 hours\")),\n",
    "                \"difficulty\": task.get(\"difficulty\", \"medium\") if task.get(\"difficulty\") in [\"easy\", \"medium\", \"hard\"] else \"medium\"\n",
    "            }\n",
    "            cleaned_subtasks.append(cleaned_task)\n",
    "        \n",
    "        data[\"subtasks\"] = cleaned_subtasks\n",
    "        return data\n",
    "    \n",
    "    def create_intelligent_fallback(self, thought: str, project_type: str = 'general', complexity: str = 'moderate') -> Dict[str, Any]:\n",
    "        thought_lower = thought.lower()\n",
    "        complexity_scores = {\"simple\": 3, \"moderate\": 5, \"complex\": 7, \"enterprise\": 9}\n",
    "        time_multipliers = {\"simple\": 0.5, \"moderate\": 1.0, \"complex\": 1.8, \"enterprise\": 3.0}\n",
    "        \n",
    "        if project_type == 'software' or any(word in thought_lower for word in [\"app\", \"website\", \"software\", \"code\"]):\n",
    "            category = \"app\"\n",
    "            base_tasks = [\n",
    "                (\"Requirements Analysis & Planning\", \"Define project scope, user stories, and technical requirements\", \"4 hours\", \"medium\"),\n",
    "                (\"Architecture & Design\", \"Create system architecture and UI/UX wireframes\", \"6 hours\", \"medium\"),\n",
    "                (\"Development Environment Setup\", \"Configure development tools, version control, and CI/CD\", \"3 hours\", \"easy\"),\n",
    "                (\"Core Feature Development\", \"Implement main application functionality\", \"16 hours\", \"hard\"),\n",
    "                (\"Testing & Quality Assurance\", \"Write tests, debug, and ensure code quality\", \"6 hours\", \"medium\"),\n",
    "                (\"Deployment & Production Setup\", \"Deploy to production and configure monitoring\", \"4 hours\", \"medium\"),\n",
    "                (\"Documentation & Handover\", \"Create user guides and technical documentation\", \"3 hours\", \"easy\")\n",
    "            ]\n",
    "        elif project_type == 'business' or any(word in thought_lower for word in [\"business\", \"startup\", \"company\"]):\n",
    "            category = \"business\"\n",
    "            base_tasks = [\n",
    "                (\"Market Research & Analysis\", \"Analyze target market, competitors, and opportunities\", \"8 hours\", \"medium\"),\n",
    "                (\"Business Model Development\", \"Define value proposition and revenue streams\", \"6 hours\", \"hard\"),\n",
    "                (\"Financial Planning & Projections\", \"Create budgets, forecasts, and funding strategy\", \"10 hours\", \"hard\"),\n",
    "                (\"Legal & Regulatory Setup\", \"Handle business registration and compliance\", \"5 hours\", \"medium\"),\n",
    "                (\"Brand Development & Marketing\", \"Create brand identity and marketing strategy\", \"8 hours\", \"medium\"),\n",
    "                (\"Operations & Team Building\", \"Establish processes and hire key team members\", \"12 hours\", \"hard\"),\n",
    "                (\"Launch & Growth Strategy\", \"Execute go-to-market plan and scale operations\", \"15 hours\", \"hard\")\n",
    "            ]\n",
    "        elif project_type == 'learning' or any(word in thought_lower for word in [\"learn\", \"study\", \"skill\"]):\n",
    "            category = \"learning\"\n",
    "            base_tasks = [\n",
    "                (\"Learning Objective Setting\", \"Define specific, measurable learning goals\", \"2 hours\", \"easy\"),\n",
    "                (\"Resource Curation & Planning\", \"Find quality materials and create study schedule\", \"3 hours\", \"easy\"),\n",
    "                (\"Foundation Building\", \"Master fundamental concepts and prerequisites\", \"12 hours\", \"medium\"),\n",
    "                (\"Practical Application\", \"Apply knowledge through projects and exercises\", \"15 hours\", \"medium\"),\n",
    "                (\"Advanced Topics & Specialization\", \"Dive deep into specialized areas\", \"20 hours\", \"hard\"),\n",
    "                (\"Portfolio Development\", \"Create projects demonstrating mastery\", \"10 hours\", \"hard\"),\n",
    "                (\"Continuous Practice & Improvement\", \"Maintain and refine skills over time\", \"8 hours\", \"medium\")\n",
    "            ]\n",
    "        else:\n",
    "            category = \"other\"\n",
    "            base_tasks = [\n",
    "                (\"Project Definition & Scope\", \"Clearly define objectives and success criteria\", \"3 hours\", \"easy\"),\n",
    "                (\"Research & Analysis\", \"Gather information and analyze requirements\", \"5 hours\", \"medium\"),\n",
    "                (\"Planning & Strategy\", \"Create detailed timeline and resource allocation\", \"4 hours\", \"medium\"),\n",
    "                (\"Initial Implementation\", \"Execute core project activities\", \"12 hours\", \"medium\"),\n",
    "                (\"Review & Iteration\", \"Evaluate progress and make improvements\", \"6 hours\", \"medium\"),\n",
    "                (\"Quality Assurance\", \"Ensure standards and requirements are met\", \"4 hours\", \"medium\"),\n",
    "                (\"Finalization & Handover\", \"Complete project and document outcomes\", \"3 hours\", \"easy\")\n",
    "            ]\n",
    "        \n",
    "        # Adjust tasks based on complexity\n",
    "        time_mult = time_multipliers.get(complexity, 1.0)\n",
    "        task_count = {\"simple\": 4, \"moderate\": 6, \"complex\": 7, \"enterprise\": 8}.get(complexity, 6)\n",
    "        \n",
    "        subtasks = []\n",
    "        for i, (title, desc, base_time, diff) in enumerate(base_tasks[:task_count], 1):\n",
    "            # Adjust time estimates based on complexity\n",
    "            base_hours = int(re.findall(r'\\d+', base_time)[0]) if re.findall(r'\\d+', base_time) else 2\n",
    "            adjusted_hours = max(1, int(base_hours * time_mult))\n",
    "            \n",
    "            if adjusted_hours >= 8:\n",
    "                time_str = f\"{adjusted_hours // 8} day{'s' if adjusted_hours // 8 > 1 else ''}\"\n",
    "            else:\n",
    "                time_str = f\"{adjusted_hours} hour{'s' if adjusted_hours > 1 else ''}\"\n",
    "            \n",
    "            subtasks.append({\n",
    "                \"id\": i,\n",
    "                \"title\": title,\n",
    "                \"description\": desc,\n",
    "                \"estimated_time\": time_str,\n",
    "                \"difficulty\": diff\n",
    "            })\n",
    "        \n",
    "        total_hours = sum(int(re.findall(r'\\d+', task[\"estimated_time\"])[0]) for task in subtasks)\n",
    "        \n",
    "        return {\n",
    "            \"main_goal\": f\"Successfully execute {complexity} {project_type} project: {thought}\",\n",
    "            \"category\": category,\n",
    "            \"priority\": \"high\" if complexity in [\"complex\", \"enterprise\"] else \"medium\",\n",
    "            \"project_type\": project_type,\n",
    "            \"complexity_score\": complexity_scores.get(complexity, 5),\n",
    "            \"total_estimated_hours\": total_hours,\n",
    "            \"subtasks\": subtasks\n",
    "        }\n",
    "    \n",
    "    def calculate_total_time(self, subtasks: List[Dict]) -> int:\n",
    "        total = 0\n",
    "        for task in subtasks:\n",
    "            time_str = task.get(\"estimated_time\", \"1 hour\").lower()\n",
    "            numbers = re.findall(r'\\d+', time_str)\n",
    "            if numbers:\n",
    "                value = int(numbers[0])\n",
    "                if 'day' in time_str:\n",
    "                    total += value * 8\n",
    "                elif 'week' in time_str:\n",
    "                    total += value * 40\n",
    "                else:  # assume hours\n",
    "                    total += value\n",
    "        return total\n",
    "\n",
    "# Initialize Enhanced AI system\n",
    "print(\"ðŸ§  Initializing Mistral Infinite Task Breakdown AI...\")\n",
    "task_ai = MistralInfiniteTaskBreakdownAI(model, tokenizer)\n",
    "print(\"âœ… Advanced AI system ready for infinite task breakdown!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸš€ FAST Test - Optimized for Kaggle Speed\n",
    "print(\"âš¡ FAST TEST: Quick Mistral 7B Validation\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Single fast test\n",
    "test_thought = \"Create a simple mobile app\"\n",
    "complexity = \"simple\"\n",
    "project_type = \"software\"\n",
    "\n",
    "print(f\"ðŸŽ¯ Testing: {test_thought}\")\n",
    "print(f\"ðŸ”§ Complexity: {complexity.upper()}\")\n",
    "print(f\"ðŸ“± Type: {project_type.upper()}\")\n",
    "print(\"ðŸ• Starting generation (should be ~30-60 seconds)...\")\n",
    "\n",
    "start_time = time.time()\n",
    "result = task_ai.generate_smart_breakdown(test_thought, project_type, complexity)\n",
    "total_time = time.time() - start_time\n",
    "\n",
    "if result[\"success\"]:\n",
    "    data = result[\"data\"]\n",
    "    print(f\"\\nâœ… SUCCESS in {total_time:.1f} seconds!\")\n",
    "    print(f\"ðŸŽ¯ Goal: {data['main_goal']}\")\n",
    "    print(f\"ðŸ“Š Subtasks: {len(data['subtasks'])}\")\n",
    "    print(f\"â±ï¸ Total Hours: {data.get('total_estimated_hours', 'N/A')}\")\n",
    "    \n",
    "    print(f\"\\nðŸ“‹ Generated Tasks:\")\n",
    "    for i, task in enumerate(data['subtasks'][:3], 1):  # Show first 3\n",
    "        print(f\"  {i}. {task['title']}\")\n",
    "        print(f\"     â±ï¸ {task['estimated_time']} | ðŸŽšï¸ {task['difficulty']}\")\n",
    "    \n",
    "    if len(data['subtasks']) > 3:\n",
    "        print(f\"  ... and {len(data['subtasks']) - 3} more tasks\")\n",
    "    \n",
    "    print(f\"\\nðŸŽ‰ Mistral 7B is working perfectly!\")\n",
    "    print(f\"ðŸš€ Ready for full testing!\")\n",
    "    \n",
    "else:\n",
    "    print(f\"âŒ Error: {result.get('error')}\")\n",
    "    print(\"ðŸ”„ Check your model loading and try again\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test Enhanced System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_thoughts = [\n",
    "    \"Create a cryptocurrency trading platform with AI predictions\",\n",
    "    \"Launch a sustainable fashion e-commerce marketplace\", \n",
    "    \"Build a machine learning course for beginners\",\n",
    "    \"Design a smart city IoT infrastructure project\"\n",
    "]\n",
    "\n",
    "complexities = ['simple', 'moderate', 'complex', 'enterprise']\n",
    "\n",
    "print(\"ðŸ§ª Testing Advanced Mistral 7B Infinite Breakdown System...\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for i, thought in enumerate(test_thoughts, 1):\n",
    "    complexity = complexities[(i-1) % len(complexities)]\n",
    "    \n",
    "    print(f\"\\nðŸŽ¯ TEST {i}: {thought}\")\n",
    "    print(f\"ðŸ”§ Complexity: {complexity.upper()}\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    # Detect project type\n",
    "    thought_lower = thought.lower()\n",
    "    if 'platform' in thought_lower or 'app' in thought_lower or 'trading' in thought_lower:\n",
    "        project_type = 'software'\n",
    "    elif 'launch' in thought_lower or 'marketplace' in thought_lower or 'business' in thought_lower:\n",
    "        project_type = 'business'\n",
    "    elif 'course' in thought_lower or 'learn' in thought_lower:\n",
    "        project_type = 'learning'\n",
    "    else:\n",
    "        project_type = 'general'\n",
    "    \n",
    "    result = task_ai.generate_smart_breakdown(thought, project_type, complexity)\n",
    "    \n",
    "    if result[\"success\"]:\n",
    "        data = result[\"data\"]\n",
    "        print(f\"ðŸŽ¯ MAIN GOAL: {data['main_goal']}\")\n",
    "        print(f\"ðŸ“‚ PROJECT TYPE: {data.get('project_type', 'N/A').upper()}\")\n",
    "        print(f\"âš¡ PRIORITY: {data['priority'].upper()}\")\n",
    "        print(f\"ðŸ”¥ COMPLEXITY: {data.get('complexity_score', 'N/A')}/10\")\n",
    "        print(f\"â±ï¸ TOTAL TIME: {data.get('total_estimated_hours', 'N/A')} hours\")\n",
    "        print(f\"ðŸš€ PROCESSING: {result.get('processing_time', 'N/A')}\")\n",
    "        print(f\"\\nðŸ“‹ INTELLIGENT SUBTASKS ({len(data['subtasks'])}):\")\n",
    "        \n",
    "        for task in data['subtasks']:\n",
    "            breakdown_indicator = \"ðŸ”„\" if (\n",
    "                task['difficulty'] != 'easy' and \n",
    "                ('hour' in task['estimated_time'] and int(re.findall(r'\\d+', task['estimated_time'])[0]) > 2 or\n",
    "                 'day' in task['estimated_time'] or 'week' in task['estimated_time'])\n",
    "            ) else \"âœ…\"\n",
    "            \n",
    "            print(f\"\\n  {breakdown_indicator} {task['id']}. {task['title']}\")\n",
    "            print(f\"     ðŸ“ {task['description']}\")\n",
    "            print(f\"     â±ï¸ {task['estimated_time']} | ðŸŽšï¸ {task['difficulty'].upper()}\")\n",
    "        \n",
    "        print(f\"\\nðŸ“Š PROJECT INSIGHTS:\")\n",
    "        print(f\"   â€¢ Can breakdown: {sum(1 for t in data['subtasks'] if t['difficulty'] != 'easy')} tasks\")\n",
    "        print(f\"   â€¢ Complexity distribution: {[t['difficulty'] for t in data['subtasks']]}\")\n",
    "        print(f\"   â€¢ Ready for infinite nested breakdown!\")\n",
    "        \n",
    "        # Test nested breakdown on first complex task\n",
    "        complex_tasks = [t for t in data['subtasks'] if t['difficulty'] in ['medium', 'hard']]\n",
    "        if complex_tasks:\n",
    "            print(f\"\\nðŸ”¬ TESTING NESTED BREAKDOWN ON: {complex_tasks[0]['title']}\")\n",
    "            nested_result = task_ai.generate_nested_breakdown(\n",
    "                complex_tasks[0], \n",
    "                data['main_goal'], \n",
    "                depth=1\n",
    "            )\n",
    "            \n",
    "            if nested_result[\"success\"] and nested_result[\"subtasks\"]:\n",
    "                print(f\"   âœ… Generated {len(nested_result['subtasks'])} sub-subtasks!\")\n",
    "                print(f\"   ðŸ’¡ Reasoning: {nested_result.get('breakdown_reasoning', 'N/A')}\")\n",
    "                for subtask in nested_result[\"subtasks\"][:3]:  # Show first 3\n",
    "                    print(f\"      â†’ {subtask['title']} ({subtask['estimated_time']})\")\n",
    "            else:\n",
    "                print(f\"   â„¹ï¸  Task doesn't need further breakdown\")\n",
    "        \n",
    "    else:\n",
    "        print(f\"âŒ Error: {result.get('error')}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "\n",
    "print(\"\\nðŸŽ‰ ADVANCED TESTING COMPLETED!\")\n",
    "print(\"ðŸš€ Mistral 7B now provides:\")\n",
    "print(\"   â€¢ Context-aware project analysis\")\n",
    "print(\"   â€¢ Adaptive complexity handling\") \n",
    "print(\"   â€¢ Infinite nested task breakdown\")\n",
    "print(\"   â€¢ Domain-specific expertise\")\n",
    "print(\"   â€¢ Realistic time estimation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enhanced Flask API Server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "import time\n",
    "from flask import Flask, request, jsonify\n",
    "from datetime import datetime\n",
    "\n",
    "# ðŸŒ Setup Ngrok Tunnel & Start Flask Server\n",
    "print(\"ðŸŒ Setting up public URL tunnel...\")\n",
    "\n",
    "# Start Flask app in background thread\n",
    "def run_flask():\n",
    "    app.run(host='0.0.0.0', port=5000, threaded=True, debug=False)\n",
    "\n",
    "flask_thread = threading.Thread(target=run_flask, daemon=True)\n",
    "flask_thread.start()\n",
    "print(\"ðŸš€ Flask server starting...\")\n",
    "\n",
    "# Wait for Flask to start\n",
    "time.sleep(5)\n",
    "\n",
    "# Create ngrok tunnel\n",
    "try:\n",
    "    print(\"ðŸ”— Creating ngrok tunnel...\")\n",
    "    public_tunnel = ngrok.connect(5000)\n",
    "    public_url = public_tunnel.public_url\n",
    "    print(f\"âœ… Ngrok tunnel created successfully!\")\n",
    "    print(f\"ðŸŒ Public URL: {public_url}\")\n",
    "    \n",
    "    # Display connection info\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"ðŸŽ‰ SHOWERLOG AI SERVER IS LIVE!\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"ðŸŒ Public URL: {public_url}\")\n",
    "    print(f\"ðŸ”— Add this to your .env.local:\")\n",
    "    print(f\"   NEXT_PUBLIC_AI_API_URL={public_url}\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âŒ Ngrok tunnel failed: {e}\")\n",
    "    print(\"ðŸ”„ Server running locally only\")\n",
    "    public_url = \"http://localhost:5000\"\n",
    "    print(f\"ðŸ  Local URL: {public_url}\")\n",
    "\n",
    "print(f\"\\nðŸš€ Available endpoints:\")\n",
    "print(f\"   â€¢ {public_url}/breakdown-smart - Intelligent task breakdown\")\n",
    "print(f\"   â€¢ {public_url}/breakdown-nested - Nested task breakdown\") \n",
    "print(f\"   â€¢ {public_url}/generate-thoughts - Random thought generation\")\n",
    "print(f\"   â€¢ {public_url}/health - Server health check\")\n",
    "print(f\"   â€¢ {public_url}/stats - Server statistics\")\n",
    "print(f\"   â€¢ {public_url}/keepalive - Keep-alive endpoint\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, request, jsonify\n",
    "from flask_cors import CORS\n",
    "from datetime import datetime\n",
    "import threading\n",
    "import time\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "app = Flask(__name__)\n",
    "CORS(app, origins=[\"*\"])\n",
    "\n",
    "# Global state\n",
    "request_count = 0\n",
    "breakdown_count = 0\n",
    "nested_breakdown_count = 0\n",
    "start_time = datetime.now()\n",
    "\n",
    "@app.route('/health', methods=['GET'])\n",
    "def health_check():\n",
    "    global request_count\n",
    "    request_count += 1\n",
    "    uptime = datetime.now() - start_time\n",
    "    \n",
    "    return jsonify({\n",
    "        \"status\": \"healthy\",\n",
    "        \"model\": \"mistralai/Mistral-7B-Instruct-v0.2\",\n",
    "        \"version\": \"infinite-breakdown-v2.0\",\n",
    "        \"uptime\": str(uptime).split('.')[0],\n",
    "        \"requests_served\": request_count,\n",
    "        \"breakdowns_generated\": breakdown_count,\n",
    "        \"nested_breakdowns\": nested_breakdown_count,\n",
    "        \"gpu_available\": torch.cuda.is_available(),\n",
    "        \"capabilities\": [\n",
    "            \"smart_breakdown\",\n",
    "            \"nested_breakdown\", \n",
    "            \"infinite_recursion\",\n",
    "            \"complexity_adaptation\",\n",
    "            \"domain_expertise\"\n",
    "        ],\n",
    "        \"timestamp\": datetime.now().isoformat()\n",
    "    })\n",
    "\n",
    "@app.route('/breakdown-smart', methods=['POST'])\n",
    "def smart_breakdown():\n",
    "    global request_count, breakdown_count\n",
    "    request_count += 1\n",
    "    start_time_req = time.time()\n",
    "    \n",
    "    try:\n",
    "        data = request.get_json()\n",
    "        \n",
    "        if not data or 'thought' not in data:\n",
    "            return jsonify({\n",
    "                \"error\": \"Missing 'thought' field\",\n",
    "                \"success\": False,\n",
    "                \"example\": {\n",
    "                    \"thought\": \"Create a mobile app\",\n",
    "                    \"project_type\": \"software\",\n",
    "                    \"complexity_level\": \"moderate\"\n",
    "                }\n",
    "            }), 400\n",
    "        \n",
    "        thought = data['thought'].strip()\n",
    "        project_type = data.get('project_type', 'general')\n",
    "        complexity = data.get('complexity_level', 'moderate')\n",
    "        \n",
    "        if len(thought) < 10:\n",
    "            return jsonify({\n",
    "                \"error\": \"Thought too short (min 10 chars)\",\n",
    "                \"success\": False\n",
    "            }), 400\n",
    "        \n",
    "        logger.info(f\"Smart breakdown: {thought[:50]}... [Type: {project_type}, Complexity: {complexity}]\")\n",
    "        \n",
    "        result = task_ai.generate_smart_breakdown(thought, project_type, complexity)\n",
    "        breakdown_count += 1\n",
    "        \n",
    "        processing_time = time.time() - start_time_req\n",
    "        \n",
    "        if result[\"success\"]:\n",
    "            response_data = {\n",
    "                \"success\": True,\n",
    "                \"data\": result[\"data\"],\n",
    "                \"processing_time\": f\"{processing_time:.2f}s\",\n",
    "                \"model\": \"mistralai/Mistral-7B-Instruct-v0.2\",\n",
    "                \"breakdown_type\": \"smart\",\n",
    "                \"project_analysis\": {\n",
    "                    \"detected_type\": project_type,\n",
    "                    \"complexity_level\": complexity,\n",
    "                    \"total_tasks\": len(result[\"data\"][\"subtasks\"]),\n",
    "                    \"breakdownable_tasks\": sum(1 for t in result[\"data\"][\"subtasks\"] \n",
    "                                             if t[\"difficulty\"] != \"easy\"),\n",
    "                },\n",
    "                \"timestamp\": datetime.now().isoformat()\n",
    "            }\n",
    "            \n",
    "            logger.info(f\"Smart breakdown successful: {len(result['data']['subtasks'])} tasks, {processing_time:.2f}s\")\n",
    "            return jsonify(response_data)\n",
    "        else:\n",
    "            logger.error(f\"Smart breakdown failed: {result.get('error')}\")\n",
    "            return jsonify({\n",
    "                \"success\": False,\n",
    "                \"error\": result.get(\"error\", \"Unknown error\"),\n",
    "                \"fallback_data\": result.get(\"data\"),\n",
    "                \"processing_time\": f\"{processing_time:.2f}s\",\n",
    "                \"timestamp\": datetime.now().isoformat()\n",
    "            }), 500\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Smart breakdown endpoint error: {str(e)}\")\n",
    "        return jsonify({\n",
    "            \"error\": f\"Server error: {str(e)}\",\n",
    "            \"success\": False,\n",
    "            \"timestamp\": datetime.now().isoformat()\n",
    "        }), 500\n",
    "\n",
    "@app.route('/breakdown-nested', methods=['POST'])\n",
    "def nested_breakdown():\n",
    "    global request_count, nested_breakdown_count\n",
    "    request_count += 1\n",
    "    nested_breakdown_count += 1\n",
    "    start_time_req = time.time()\n",
    "    \n",
    "    try:\n",
    "        data = request.get_json()\n",
    "        \n",
    "        required_fields = ['parent_task', 'context', 'depth']\n",
    "        if not data or not all(field in data for field in required_fields):\n",
    "            return jsonify({\n",
    "                \"error\": f\"Missing required fields: {required_fields}\",\n",
    "                \"success\": False,\n",
    "                \"example\": {\n",
    "                    \"parent_task\": {\n",
    "                        \"title\": \"Task title\",\n",
    "                        \"description\": \"Task description\", \n",
    "                        \"difficulty\": \"medium\",\n",
    "                        \"estimated_time\": \"4 hours\"\n",
    "                    },\n",
    "                    \"context\": \"Project context\",\n",
    "                    \"depth\": 1,\n",
    "                    \"max_depth\": 5\n",
    "                }\n",
    "            }), 400\n",
    "        \n",
    "        parent_task = data['parent_task']\n",
    "        context = data['context']\n",
    "        depth = data['depth']\n",
    "        max_depth = data.get('max_depth', 5)\n",
    "        \n",
    "        if depth >= max_depth:\n",
    "            return jsonify({\n",
    "                \"success\": False,\n",
    "                \"error\": f\"Maximum depth ({max_depth}) reached\",\n",
    "                \"subtasks\": [],\n",
    "                \"depth_level\": depth\n",
    "            })\n",
    "        \n",
    "        logger.info(f\"Nested breakdown: {parent_task.get('title', 'Unknown')[:30]}... [Depth: {depth}]\")\n",
    "        \n",
    "        result = task_ai.generate_nested_breakdown(parent_task, context, depth)\n",
    "        \n",
    "        processing_time = time.time() - start_time_req\n",
    "        \n",
    "        response_data = {\n",
    "            \"success\": result[\"success\"],\n",
    "            \"subtasks\": result.get(\"subtasks\", []),\n",
    "            \"breakdown_reasoning\": result.get(\"breakdown_reasoning\", \"\"),\n",
    "            \"depth_level\": depth,\n",
    "            \"processing_time\": f\"{processing_time:.2f}s\",\n",
    "            \"model\": \"mistralai/Mistral-7B-Instruct-v0.2\",\n",
    "            \"breakdown_type\": \"nested\",\n",
    "            \"parent_task_title\": parent_task.get('title', 'Unknown'),\n",
    "            \"generated_subtasks\": len(result.get(\"subtasks\", [])),\n",
    "            \"timestamp\": datetime.now().isoformat()\n",
    "        }\n",
    "        \n",
    "        if result[\"success\"]:\n",
    "            logger.info(f\"Nested breakdown successful: {len(result.get('subtasks', []))} subtasks at depth {depth}\")\n",
    "        else:\n",
    "            logger.warning(f\"Nested breakdown returned no tasks: {result.get('error', 'No reason given')}\")\n",
    "        \n",
    "        return jsonify(response_data)\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Nested breakdown endpoint error: {str(e)}\")\n",
    "        return jsonify({\n",
    "            \"error\": f\"Server error: {str(e)}\",\n",
    "            \"success\": False,\n",
    "            \"subtasks\": [],\n",
    "            \"depth_level\": data.get('depth', 0),\n",
    "            \"timestamp\": datetime.now().isoformat()\n",
    "        }), 500\n",
    "\n",
    "@app.route('/breakdown', methods=['POST'])\n",
    "def legacy_breakdown():\n",
    "    \"\"\"Legacy endpoint for backwards compatibility\"\"\"\n",
    "    data = request.get_json()\n",
    "    \n",
    "    # Convert to smart breakdown\n",
    "    if data and 'thought' in data:\n",
    "        data['project_type'] = 'general'\n",
    "        data['complexity_level'] = 'moderate'\n",
    "        \n",
    "        # Forward to smart breakdown\n",
    "        request.json = data\n",
    "        return smart_breakdown()\n",
    "    else:\n",
    "        return jsonify({\n",
    "            \"error\": \"Missing 'thought' field\",\n",
    "            \"success\": False\n",
    "        }), 400\n",
    "\n",
    "@app.route('/generate-thoughts', methods=['GET'])\n",
    "def generate_thoughts():\n",
    "    global request_count\n",
    "    request_count += 1\n",
    "    \n",
    "    thoughts_by_category = {\n",
    "        # Technology & Development\n",
    "        \"software\": [\n",
    "            \"Build a simple to-do app for my daily tasks\",\n",
    "            \"Create a personal website to showcase my hobbies\",\n",
    "            \"Learn to code and build my first project\",\n",
    "            \"Make a calculator app with a nice design\"\n",
    "        ],\n",
    "        \"web\": [\n",
    "            \"Create a blog about my interests and experiences\",\n",
    "            \"Build a simple portfolio website for myself\",\n",
    "            \"Make a landing page for a small business idea\",\n",
    "            \"Design a website for my local community group\"\n",
    "        ],\n",
    "        \"mobile\": [\n",
    "            \"Create a simple habit tracking app\",\n",
    "            \"Build a grocery list app for my family\",\n",
    "            \"Make a photo journal app for daily memories\",\n",
    "            \"Design a water drinking reminder app\"\n",
    "        ],\n",
    "        \"ai\": [\n",
    "            \"Learn the basics of artificial intelligence\",\n",
    "            \"Understand how recommendation systems work\",\n",
    "            \"Explore simple machine learning concepts\",\n",
    "            \"Try out AI tools for everyday tasks\"\n",
    "        ],\n",
    "        \n",
    "        # Business & Finance\n",
    "        \"business\": [\n",
    "            \"Start a small online business selling handmade items\",\n",
    "            \"Create a budget plan for my monthly expenses\",\n",
    "            \"Learn basic investing with small amounts\",\n",
    "            \"Plan a garage sale to declutter and earn money\"\n",
    "        ],\n",
    "        \"startup\": [\n",
    "            \"Turn my hobby into a side income\",\n",
    "            \"Start a pet-sitting service in my neighborhood\",\n",
    "            \"Create a simple service to help busy families\",\n",
    "            \"Launch a small tutoring business for local students\"\n",
    "        ],\n",
    "        \"finance\": [\n",
    "            \"Create an emergency fund with $1000\",\n",
    "            \"Learn to track my spending better\",\n",
    "            \"Plan to pay off my credit card debt\",\n",
    "            \"Start saving for a vacation next year\"\n",
    "        ],\n",
    "        \"marketing\": [\n",
    "            \"Promote my small business on social media\",\n",
    "            \"Help a friend advertise their garage sale\",\n",
    "            \"Create content to share my expertise online\",\n",
    "            \"Start a simple newsletter for my community\"\n",
    "        ],\n",
    "        \n",
    "        # Creative & Arts\n",
    "        \"creative\": [\n",
    "            \"Start a daily drawing or sketching practice\",\n",
    "            \"Write short stories about my daily experiences\",\n",
    "            \"Create handmade gifts for family and friends\",\n",
    "            \"Document my life through creative photography\"\n",
    "        ],\n",
    "        \"art\": [\n",
    "            \"Learn watercolor painting as a relaxing hobby\",\n",
    "            \"Create art using recycled materials from home\",\n",
    "            \"Start a small art journal with daily sketches\",\n",
    "            \"Make decorative pieces for my living space\"\n",
    "        ],\n",
    "        \"music\": [\n",
    "            \"Learn to play my favorite song on guitar\",\n",
    "            \"Create simple beats using free music software\",\n",
    "            \"Start a small podcast about topics I love\",\n",
    "            \"Learn basic ukulele to play around campfires\"\n",
    "        ],\n",
    "        \"photography\": [\n",
    "            \"Take better photos of my family gatherings\",\n",
    "            \"Document my neighborhood's changing seasons\",\n",
    "            \"Create a photo album of local coffee shops\",\n",
    "            \"Learn smartphone photography techniques\"\n",
    "        ],\n",
    "        \n",
    "        # Health & Wellness\n",
    "        \"fitness\": [\n",
    "            \"Start walking 30 minutes every day\",\n",
    "            \"Learn basic yoga poses for morning stretches\",\n",
    "            \"Plan workouts I can do at home without equipment\",\n",
    "            \"Train to walk/run a local 5K event\"\n",
    "        ],\n",
    "        \"nutrition\": [\n",
    "            \"Learn to meal prep for busy weekdays\",\n",
    "            \"Try cooking one new healthy recipe each week\",\n",
    "            \"Start growing herbs on my windowsill\",\n",
    "            \"Plan balanced meals on a budget\"\n",
    "        ],\n",
    "        \"beauty\": [\n",
    "            \"Develop a simple skincare routine that works\",\n",
    "            \"Learn basic makeup techniques for everyday wear\",\n",
    "            \"Try DIY face masks using kitchen ingredients\",\n",
    "            \"Create a capsule wardrobe with pieces I love\"\n",
    "        ],\n",
    "        \"mental_health\": [\n",
    "            \"Start a 5-minute daily meditation practice\",\n",
    "            \"Keep a gratitude journal for better mood\",\n",
    "            \"Learn stress management techniques for work\",\n",
    "            \"Create a calming bedtime routine\"\n",
    "        ],\n",
    "        \n",
    "        # Education & Learning\n",
    "        \"learning\": [\n",
    "            \"Learn a new language using free apps\",\n",
    "            \"Take an online course about something I'm curious about\",\n",
    "            \"Read one book per month on topics I enjoy\",\n",
    "            \"Practice a skill for 15 minutes daily\"\n",
    "        ],\n",
    "        \"language\": [\n",
    "            \"Learn basic Spanish for my next vacation\",\n",
    "            \"Practice English conversation with language partners\",\n",
    "            \"Learn common phrases in my neighbor's language\",\n",
    "            \"Understand the basics of sign language\"\n",
    "        ],\n",
    "        \"teaching\": [\n",
    "            \"Teach my kids a skill I know well\",\n",
    "            \"Share my expertise with friends who are interested\",\n",
    "            \"Create simple tutorials for things I've learned\",\n",
    "            \"Mentor someone who's just starting in my field\"\n",
    "        ],\n",
    "        \n",
    "        # Sports & Recreation  \n",
    "        \"sports\": [\n",
    "            \"Join a local recreational sports league\",\n",
    "            \"Learn to ride a bike or improve my cycling\",\n",
    "            \"Try a new sport like tennis or badminton\",\n",
    "            \"Organize neighborhood games for kids and families\"\n",
    "        ],\n",
    "        \"dancing\": [\n",
    "            \"Learn basic dance moves for social events\",\n",
    "            \"Try online dance tutorials for fun exercise\",\n",
    "            \"Take a beginner's class in a style I like\",\n",
    "            \"Practice dancing to my favorite songs at home\"\n",
    "        ],\n",
    "        \"outdoor\": [\n",
    "            \"Explore hiking trails in my local area\",\n",
    "            \"Plan fun camping trips with family or friends\",\n",
    "            \"Create a backyard garden space for relaxation\",\n",
    "            \"Try geocaching or nature scavenger hunts\"\n",
    "        ],\n",
    "        \n",
    "        # Personal Development & Relationships\n",
    "        \"relationships\": [\n",
    "            \"Plan more quality time with family and friends\",\n",
    "            \"Learn better communication skills for work and home\",\n",
    "            \"Organize regular gatherings with people I care about\",\n",
    "            \"Practice being a better listener in conversations\"\n",
    "        ],\n",
    "        \"personal\": [\n",
    "            \"Create a morning routine that energizes me\",\n",
    "            \"Set and achieve small personal goals each month\",\n",
    "            \"Learn to say no to commitments that drain me\",\n",
    "            \"Develop confidence in public speaking\"\n",
    "        ],\n",
    "        \"parenting\": [\n",
    "            \"Plan fun educational activities for my children\",\n",
    "            \"Create family traditions that bring us closer\",\n",
    "            \"Learn positive discipline techniques that work\",\n",
    "            \"Organize playdates and social activities for kids\"\n",
    "        ],\n",
    "        \n",
    "        # Home & Lifestyle\n",
    "        \"cooking\": [\n",
    "            \"Master 5 simple, delicious weeknight dinners\",\n",
    "            \"Learn to bake bread or cookies from scratch\",\n",
    "            \"Try cooking cuisines from different cultures\",\n",
    "            \"Organize my kitchen for easier meal preparation\"\n",
    "        ],\n",
    "        \"gardening\": [\n",
    "            \"Start a small vegetable garden in my backyard\",\n",
    "            \"Learn to care for houseplants successfully\",\n",
    "            \"Create a flower garden to attract butterflies\",\n",
    "            \"Grow fresh herbs for cooking on my balcony\"\n",
    "        ],\n",
    "        \"home\": [\n",
    "            \"Organize and declutter one room at a time\",\n",
    "            \"Redecorate my living space on a budget\",\n",
    "            \"Learn basic home maintenance skills\",\n",
    "            \"Create cozy spaces for reading and relaxation\"\n",
    "        ],\n",
    "        \n",
    "        # Career & Professional\n",
    "        \"career\": [\n",
    "            \"Update my resume and LinkedIn profile\",\n",
    "            \"Learn a new skill that could help at work\",\n",
    "            \"Network with colleagues in my field\",\n",
    "            \"Set professional goals for the next year\"\n",
    "        ],\n",
    "        \"job_hunting\": [\n",
    "            \"Prepare for job interviews with practice questions\",\n",
    "            \"Research companies I'd like to work for\",\n",
    "            \"Improve my professional online presence\",\n",
    "            \"Practice explaining my experience clearly\"\n",
    "        ],\n",
    "        \n",
    "        # Science & Environment\n",
    "        \"science\": [\n",
    "            \"Learn about local wildlife and ecosystems\",\n",
    "            \"Start composting kitchen scraps at home\",\n",
    "            \"Understand basic astronomy and stargazing\",\n",
    "            \"Explore simple science experiments with kids\"\n",
    "        ],\n",
    "        \"environment\": [\n",
    "            \"Reduce plastic use in my daily routine\",\n",
    "            \"Start recycling more effectively at home\",\n",
    "            \"Choose eco-friendly alternatives for cleaning\",\n",
    "            \"Participate in local community cleanup events\"\n",
    "        ],\n",
    "        \n",
    "        # Unique & Diverse Categories\n",
    "        \"travel\": [\n",
    "            \"Plan affordable weekend trips to nearby cities\",\n",
    "            \"Explore interesting places in my own city\",\n",
    "            \"Learn about different cultures through food and events\",\n",
    "            \"Create a travel savings plan for future adventures\"\n",
    "        ],\n",
    "        \"volunteer\": [\n",
    "            \"Help at a local food bank or charity\",\n",
    "            \"Volunteer at community events and festivals\",\n",
    "            \"Assist elderly neighbors with simple tasks\",\n",
    "            \"Participate in local school or library programs\"\n",
    "        ],\n",
    "        \"hobby\": [\n",
    "            \"Learn a craft like knitting, woodworking, or pottery\",\n",
    "            \"Start collecting something interesting and affordable\",\n",
    "            \"Join a local club related to my interests\",\n",
    "            \"Try different hobbies to find what I enjoy most\"\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    import random\n",
    "    \n",
    "    # Select diverse thoughts from different categories\n",
    "    selected = []\n",
    "    categories = list(thoughts_by_category.keys())\n",
    "    \n",
    "    for _ in range(3):\n",
    "        category = random.choice(categories)\n",
    "        thought = random.choice(thoughts_by_category[category])\n",
    "        selected.append({\n",
    "            \"thought\": thought,\n",
    "            \"suggested_type\": category,\n",
    "            \"suggested_complexity\": random.choice([\"moderate\", \"complex\"])\n",
    "        })\n",
    "    \n",
    "    return jsonify({\n",
    "        \"success\": True,\n",
    "        \"thoughts\": [item[\"thought\"] for item in selected],\n",
    "        \"enhanced_suggestions\": selected,\n",
    "        \"categories\": categories,\n",
    "        \"total_available\": sum(len(thoughts) for thoughts in thoughts_by_category.values()),\n",
    "        \"timestamp\": datetime.now().isoformat()\n",
    "    })\n",
    "\n",
    "@app.route('/stats', methods=['GET'])\n",
    "def get_stats():\n",
    "    uptime = datetime.now() - start_time\n",
    "    \n",
    "    return jsonify({\n",
    "        \"uptime\": str(uptime).split('.')[0],\n",
    "        \"requests_served\": request_count,\n",
    "        \"breakdowns_generated\": breakdown_count,\n",
    "        \"nested_breakdowns\": nested_breakdown_count,\n",
    "        \"model\": \"mistralai/Mistral-7B-Instruct-v0.2\",\n",
    "        \"version\": \"infinite-breakdown-v2.0\",\n",
    "        \"gpu_memory_gb\": torch.cuda.get_device_properties(0).total_memory / 1024**3 if torch.cuda.is_available() else None,\n",
    "        \"status\": \"operational\",\n",
    "        \"capabilities\": {\n",
    "            \"smart_breakdown\": True,\n",
    "            \"nested_breakdown\": True,\n",
    "            \"infinite_recursion\": True,\n",
    "            \"complexity_adaptation\": True,\n",
    "            \"domain_expertise\": True,\n",
    "            \"max_depth\": 5\n",
    "        },\n",
    "        \"timestamp\": datetime.now().isoformat()\n",
    "    })\n",
    "\n",
    "# Add keep-alive endpoint for external monitoring\n",
    "@app.route('/keepalive')\n",
    "def keepalive_endpoint():\n",
    "    \"\"\"Dedicated endpoint for external keep-alive pings\"\"\"\n",
    "    return jsonify({\n",
    "        'status': 'alive',\n",
    "        'uptime': str(datetime.now() - start_time).split('.')[0],\n",
    "        'requests': request_count,\n",
    "        'breakdown_count': breakdown_count,\n",
    "        'memory_mb': torch.cuda.memory_allocated() / 1024**2 if torch.cuda.is_available() else 0,\n",
    "        'timestamp': datetime.now().isoformat(),\n",
    "        'model_loaded': 'model' in globals(),\n",
    "        'gpu_available': torch.cuda.is_available()\n",
    "    })\n",
    "\n",
    "\n",
    "print(\"âœ… Enhanced Flask API server ready!\")\n",
    "print(\"ðŸš€ Advanced Endpoints available:\")\n",
    "print(\"   â€¢ /breakdown-smart (POST) - Intelligent task breakdown\")\n",
    "print(\"   â€¢ /breakdown-nested (POST) - Infinite nested breakdown\")\n",
    "print(\"   â€¢ /breakdown (POST) - Legacy compatibility\")\n",
    "print(\"   â€¢ /generate-thoughts (GET) - Enhanced thought generation\")\n",
    "print(\"   â€¢ /health (GET) - Health check with capabilities\")\n",
    "print(\"   â€¢ /stats (GET) - Detailed server statistics\")\n",
    "print(\"   â€¢ /keepalive (GET) - Keep-alive monitoring endpoint\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸ”§ EMERGENCY FIX: Ensure public_url is defined\n",
    "try:\n",
    "    # Check if public_url exists from ngrok setup\n",
    "    if 'public_url' not in globals():\n",
    "        print(\"âš ï¸ Public URL not defined, setting up now...\")\n",
    "        \n",
    "        # Try to get ngrok tunnel info\n",
    "        try:\n",
    "            tunnels = ngrok.get_tunnels()\n",
    "            if tunnels:\n",
    "                public_url = tunnels[0].public_url\n",
    "                print(f\"âœ… Found existing tunnel: {public_url}\")\n",
    "            else:\n",
    "                print(\"ðŸ”— Creating new ngrok tunnel...\")\n",
    "                tunnel = ngrok.connect(5000)\n",
    "                public_url = tunnel.public_url\n",
    "                print(f\"âœ… New tunnel created: {public_url}\")\n",
    "        except Exception as ngrok_error:\n",
    "            print(f\"âŒ Ngrok failed: {ngrok_error}\")\n",
    "            public_url = \"http://localhost:5000\"\n",
    "            print(f\"ðŸ  Using local URL: {public_url}\")\n",
    "    \n",
    "    # Display the critical information\n",
    "    print(\"\\n\" + \"ðŸŒŸ\" * 70)\n",
    "    print(\"ðŸŽ‰ SHOWERLOG AI SERVER IS READY!\")\n",
    "    print(\"ðŸŒŸ\" * 70)\n",
    "    print(f\"ðŸŒ Public URL: {public_url}\")\n",
    "    print(f\"ðŸ§  Model: Mistral-7B-Instruct (Kaggle Optimized)\")\n",
    "    print(f\"ðŸš€ Status: Ready for requests\")\n",
    "    print(\"\\nðŸŽ¯ IMPORTANT: Add this to your .env.local file:\")\n",
    "    print(f\"NEXT_PUBLIC_AI_API_URL={public_url}\")\n",
    "    print(\"\\nðŸ“± Test endpoints:\")\n",
    "    print(f\"  â€¢ Health: {public_url}/health\")\n",
    "    print(f\"  â€¢ Stats: {public_url}/stats\") \n",
    "    print(f\"  â€¢ Keep-alive: {public_url}/keepalive\")\n",
    "    print(\"ðŸŒŸ\" * 70)\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"ðŸš¨ Setup error: {e}\")\n",
    "    public_url = \"http://localhost:5000\"\n",
    "    print(f\"ðŸ  Fallback URL: {public_url}\")\n",
    "    print(f\"ðŸ”§ Add to .env.local: NEXT_PUBLIC_AI_API_URL={public_url}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Advanced Timeout Prevention System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enhanced Keep-Alive with Aggressive Timeout Prevention\n",
    "import time\n",
    "import threading\n",
    "from datetime import datetime, timedelta\n",
    "import json\n",
    "import gc\n",
    "import os\n",
    "import random\n",
    "import psutil\n",
    "\n",
    "class KaggleKeepAlive:\n",
    "    def __init__(self):\n",
    "        self.start_time = datetime.now()\n",
    "        self.last_activity = datetime.now()\n",
    "        self.is_running = True\n",
    "        self.request_count = 0\n",
    "        self.activity_count = 0\n",
    "        self.stats = {\n",
    "            'uptime': '0:00:00',\n",
    "            'activities_performed': 0,\n",
    "            'last_activity': 'None',\n",
    "            'memory_usage': '0 MB',\n",
    "            'gpu_usage': '0 MB',\n",
    "            'model_status': 'Ready',\n",
    "            'cpu_activity': 0,\n",
    "            'timeout_prevention': 'Active',\n",
    "            'threads_running': 0\n",
    "        }\n",
    "        \n",
    "    def aggressive_activity_simulation(self):\n",
    "        \"\"\"Multiple activity strategies to prevent timeout\"\"\"\n",
    "        while self.is_running:\n",
    "            try:\n",
    "                current_time = datetime.now()\n",
    "                uptime = current_time - self.start_time\n",
    "                self.stats['uptime'] = str(uptime).split('.')[0]\n",
    "                \n",
    "                # Activity 1: CPU computation\n",
    "                cpu_work = sum(i**2 for i in range(500 + random.randint(0, 500)))\n",
    "                self.stats['cpu_activity'] = cpu_work % 1000\n",
    "                \n",
    "                # Activity 2: Memory operations\n",
    "                temp_data = [random.random() for _ in range(1000)]\n",
    "                processed = [x * 2 for x in temp_data[:500]]\n",
    "                self.stats['memory_usage'] = f\"{psutil.virtual_memory().used / (1024**2):.1f} MB\"\n",
    "                del temp_data, processed\n",
    "                \n",
    "                # Activity 3: GPU memory check (if available)\n",
    "                if torch.cuda.is_available():\n",
    "                    gpu_mem = torch.cuda.memory_allocated() / (1024**2)\n",
    "                    self.stats['gpu_usage'] = f\"{gpu_mem:.1f} MB\"\n",
    "                    # Touch GPU memory\n",
    "                    dummy_tensor = torch.randn(100, 100).cuda()\n",
    "                    result = dummy_tensor.sum()\n",
    "                    del dummy_tensor\n",
    "                \n",
    "                # Activity 4: File I/O operations\n",
    "                temp_file = f'/tmp/keepalive_{random.randint(1000, 9999)}.txt'\n",
    "                with open(temp_file, 'w') as f:\n",
    "                    f.write(f\"Active at {current_time}\\n{random.random()}\")\n",
    "                if os.path.exists(temp_file):\n",
    "                    with open(temp_file, 'r') as f:\n",
    "                        content = f.read()\n",
    "                    os.remove(temp_file)\n",
    "                \n",
    "                # Activity 5: Model interaction every 8 minutes\n",
    "                if current_time.minute % 8 == 0 and current_time.second < 10:\n",
    "                    try:\n",
    "                        print(\"ðŸ”¥ Model warmup - preventing timeout...\")\n",
    "                        warmup_thought = ai_service.generate_random_thought()\n",
    "                        print(f\"ðŸ’­ Warmup: {warmup_thought[:50]}...\")\n",
    "                        self.stats['model_status'] = 'Warmed'\n",
    "                    except Exception as e:\n",
    "                        print(f\"âš ï¸ Warmup warning: {e}\")\n",
    "                        self.stats['model_status'] = f'Warning: {str(e)[:20]}'\n",
    "                \n",
    "                # Activity 6: Garbage collection (every 15 minutes)\n",
    "                if current_time.minute % 15 == 0 and current_time.second < 5:\n",
    "                    gc.collect()\n",
    "                    if torch.cuda.is_available():\n",
    "                        torch.cuda.empty_cache()\n",
    "                    print(\"ðŸ§¹ Memory cleanup completed\")\n",
    "                \n",
    "                # Activity 7: Network simulation\n",
    "                try:\n",
    "                    import requests\n",
    "                    response = requests.get('https://httpbin.org/uuid', timeout=3)\n",
    "                    if response.status_code == 200:\n",
    "                        uuid_data = response.json()\n",
    "                except:\n",
    "                    pass  # Ignore network errors\n",
    "                \n",
    "                self.activity_count += 1\n",
    "                self.stats['activities_performed'] = self.activity_count\n",
    "                self.stats['last_activity'] = current_time.strftime('%H:%M:%S')\n",
    "                \n",
    "                # Status display every 2 minutes\n",
    "                if current_time.minute % 2 == 0 and current_time.second < 10:\n",
    "                    self.display_status()\n",
    "                \n",
    "                # Variable sleep to appear more natural\n",
    "                sleep_time = random.uniform(20, 40)  # 20-40 seconds\n",
    "                time.sleep(sleep_time)\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"âš ï¸ Activity simulation error: {e}\")\n",
    "                time.sleep(30)\n",
    "    \n",
    "    def emergency_prevention(self):\n",
    "        \"\"\"Emergency timeout prevention with micro-activities\"\"\"\n",
    "        while self.is_running:\n",
    "            try:\n",
    "                # Continuous micro-activities every 10 seconds\n",
    "                for i in range(60):  # 10 minutes of micro-activities\n",
    "                    if not self.is_running:\n",
    "                        break\n",
    "                    \n",
    "                    # Micro CPU work\n",
    "                    result = sum(range(random.randint(50, 200)))\n",
    "                    \n",
    "                    # Memory micro-allocation\n",
    "                    temp_list = [random.random() for _ in range(random.randint(10, 50))]\n",
    "                    temp_sum = sum(temp_list)\n",
    "                    del temp_list\n",
    "                    \n",
    "                    # Random mathematical operations\n",
    "                    math_result = random.random() ** 0.5 * random.randint(1, 100)\n",
    "                    \n",
    "                    time.sleep(10)  # 10-second intervals\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"Emergency prevention error: {e}\")\n",
    "                time.sleep(60)\n",
    "    \n",
    "    def model_interaction_loop(self):\n",
    "        \"\"\"Dedicated thread for model interactions\"\"\"\n",
    "        while self.is_running:\n",
    "            try:\n",
    "                time.sleep(300)  # Every 5 minutes\n",
    "                if self.is_running:\n",
    "                    # Test different model capabilities\n",
    "                    test_cases = [\n",
    "                        (\"organize my desk\", \"simple\"),\n",
    "                        (\"learn a new skill\", \"moderate\"),\n",
    "                        (\"start a small business\", \"complex\")\n",
    "                    ]\n",
    "                    \n",
    "                    test_case = random.choice(test_cases)\n",
    "                    thought, complexity = test_case\n",
    "                    \n",
    "                    # Generate breakdown to keep model active\n",
    "                    result = ai_service.generate_task_breakdown(thought, complexity, max_subtasks=3)\n",
    "                    \n",
    "                    if result and 'subtasks' in result:\n",
    "                        subtask_count = len(result.get('subtasks', []))\n",
    "                        print(f\"ðŸ§  Model interaction successful: {subtask_count} subtasks for '{thought}'\")\n",
    "                        self.stats['model_status'] = f'Active ({subtask_count} tasks)'\n",
    "                    else:\n",
    "                        print(\"ðŸ§  Model interaction completed (fallback used)\")\n",
    "                        self.stats['model_status'] = 'Active (fallback)'\n",
    "                        \n",
    "            except Exception as e:\n",
    "                print(f\"Model interaction error: {e}\")\n",
    "                self.stats['model_status'] = f'Error: {str(e)[:20]}'\n",
    "                time.sleep(300)\n",
    "    \n",
    "    def display_status(self):\n",
    "        \"\"\"Display comprehensive status\"\"\"\n",
    "        current_time = datetime.now()\n",
    "        print(\"\\n\" + \"ðŸš¿\" * 25)\n",
    "        print(f\"ðŸš¿ ShowerThoughts AI Server Status\")\n",
    "        print(f\"ðŸš¿ {current_time.strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "        print(\"ðŸš¿\" * 25)\n",
    "        print(f\"â° Uptime: {self.stats['uptime']}\")\n",
    "        print(f\"ðŸ”¥ Activities: {self.stats['activities_performed']}\")\n",
    "        print(f\"ðŸ“Š API Requests: {request_count}\")\n",
    "        print(f\"ðŸ’¾ Memory: {self.stats['memory_usage']}\")\n",
    "        print(f\"ðŸŽ® GPU Memory: {self.stats['gpu_usage']}\")\n",
    "        print(f\"ðŸ¤– Model: {self.stats['model_status']}\")\n",
    "        print(f\"âš¡ CPU Work: {self.stats['cpu_activity']}\")\n",
    "        print(f\"ðŸ›¡ï¸ Prevention: {self.stats['timeout_prevention']}\")\n",
    "        print(f\"ðŸ• Last Activity: {self.stats['last_activity']}\")\n",
    "        print(f\"ðŸ§µ Threads: {threading.active_count()}\")\n",
    "        print(\"ðŸš¿\" * 25 + \"\\n\")\n",
    "    \n",
    "    def update_activity(self):\n",
    "        \"\"\"Update activity with enhanced tracking\"\"\"\n",
    "        self.last_activity = datetime.now()\n",
    "        self.request_count += 1\n",
    "        self.stats['model_status'] = 'Request Active'\n",
    "        \n",
    "        # Burst activity after requests\n",
    "        burst_work = sum(i**3 for i in range(100))\n",
    "        temp_data = [random.random() for _ in range(500)]\n",
    "        del temp_data\n",
    "        \n",
    "    def stop(self):\n",
    "        \"\"\"Stop all keep-alive services\"\"\"\n",
    "        self.is_running = False\n",
    "        print(\"ðŸ›‘ All keep-alive services stopped\")\n",
    "\n",
    "# Initialize enhanced keep-alive system\n",
    "print(\"ðŸŽ¯ Starting Comprehensive Timeout Prevention System...\")\n",
    "keep_alive = KaggleKeepAlive()\n",
    "\n",
    "# Start multiple redundant threads\n",
    "print(\"ðŸš€ Launching multiple protection threads...\")\n",
    "\n",
    "# Thread 1: Aggressive activity simulation\n",
    "activity_thread = threading.Thread(target=keep_alive.aggressive_activity_simulation, daemon=True)\n",
    "activity_thread.start()\n",
    "print(\"âœ… Activity simulation thread started\")\n",
    "\n",
    "# Thread 2: Emergency prevention\n",
    "emergency_thread = threading.Thread(target=keep_alive.emergency_prevention, daemon=True)\n",
    "emergency_thread.start()\n",
    "print(\"âœ… Emergency prevention thread started\")\n",
    "\n",
    "# Thread 3: Model interactions\n",
    "model_thread = threading.Thread(target=keep_alive.model_interaction_loop, daemon=True)\n",
    "model_thread.start()\n",
    "print(\"âœ… Model interaction thread started\")\n",
    "\n",
    "# Thread 4: Additional protection layer\n",
    "def extra_protection():\n",
    "    while keep_alive.is_running:\n",
    "        try:\n",
    "            # Random computational tasks\n",
    "            for _ in range(10):\n",
    "                work = [i * random.random() for i in range(random.randint(100, 500))]\n",
    "                result = sum(work) / len(work) if work else 0\n",
    "                del work\n",
    "                time.sleep(random.uniform(30, 60))\n",
    "        except Exception as e:\n",
    "            print(f\"Extra protection error: {e}\")\n",
    "            time.sleep(60)\n",
    "\n",
    "extra_thread = threading.Thread(target=extra_protection, daemon=True)\n",
    "extra_thread.start()\n",
    "print(\"âœ… Extra protection thread started\")\n",
    "\n",
    "# Update Flask app to track activity\n",
    "@app.before_request\n",
    "def before_request():\n",
    "    \"\"\"Track all requests for activity monitoring\"\"\"\n",
    "    keep_alive.update_activity()\n",
    "\n",
    "# Display system readiness\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ðŸš¿ SHOWERTHOUGHTS AI SERVER - FULLY PROTECTED!\")\n",
    "print(\"=\"*70)\n",
    "print(f\"ðŸŒ Public URL: {public_url}\")\n",
    "print(f\"ðŸ§  Model: Mistral-7B-Instruct (4-bit optimized)\")\n",
    "print(f\"ðŸ’¾ Memory: {keep_alive.stats['memory_usage']}\")\n",
    "print(f\"ðŸŽ² Random Thoughts: 50+ accessible categories\")\n",
    "print(f\"ðŸ”„ Infinite Breakdown: Up to 5 levels deep\")\n",
    "print(f\"ðŸ›¡ï¸ Timeout Prevention: {threading.active_count()} threads active\")\n",
    "print(f\"ðŸ“Š Keep-Alive Endpoint: {public_url}/keepalive\")\n",
    "print(f\"ðŸ”¥ Activities Running: {keep_alive.stats['activities_performed']}\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Enhanced main loop with maximum activity\n",
    "print(\"ðŸŽ® Starting maximum activity main loop...\")\n",
    "iteration_count = 0\n",
    "\n",
    "try:\n",
    "    while True:\n",
    "        iteration_count += 1\n",
    "        current_time = datetime.now()\n",
    "        \n",
    "        # Intense activity burst every iteration\n",
    "        activity_burst = {\n",
    "            'iteration': iteration_count,\n",
    "            'timestamp': current_time.isoformat(),\n",
    "            'random_work': sum(random.randint(1, 1000) for _ in range(100)),\n",
    "            'memory_work': [random.random() for _ in range(random.randint(500, 1500))]\n",
    "        }\n",
    "        \n",
    "        # Mathematical computations\n",
    "        math_intensive = sum(i**2.5 for i in range(1, random.randint(100, 500)))\n",
    "        \n",
    "        # Memory allocation and deallocation\n",
    "        large_data = list(range(random.randint(5000, 15000)))\n",
    "        processed = [x * random.random() for x in large_data[:random.randint(1000, 3000)]]\n",
    "        del large_data, processed\n",
    "        \n",
    "        # Periodic mega-activities\n",
    "        if iteration_count % 15 == 0:  # Every ~2.5 minutes\n",
    "            print(f\"ðŸš€ MEGA ACTIVITY BURST #{iteration_count // 15}\")\n",
    "            \n",
    "            # CPU mega-task\n",
    "            mega_calc = sum(i**3 for i in range(2000))\n",
    "            \n",
    "            # Memory mega-operations\n",
    "            mega_data = [random.random() for _ in range(20000)]\n",
    "            mega_processed = [x**0.5 for x in mega_data[:5000]]\n",
    "            mega_result = sum(mega_processed) / len(mega_processed)\n",
    "            del mega_data, mega_processed\n",
    "            \n",
    "            # GPU mega-activity (if available)\n",
    "            if torch.cuda.is_available():\n",
    "                mega_tensor = torch.randn(500, 500).cuda()\n",
    "                mega_gpu_result = mega_tensor.sum().item()\n",
    "                del mega_tensor\n",
    "            \n",
    "            # Model mega-ping\n",
    "            try:\n",
    "                mega_ping = ai_service.generate_random_thought()\n",
    "                print(f\"ðŸ§  MEGA model ping: {len(mega_ping)} chars generated\")\n",
    "            except Exception as e:\n",
    "                print(f\"ðŸ§  MEGA ping warning: {e}\")\n",
    "            \n",
    "            # Status update\n",
    "            keep_alive.display_status()\n",
    "        \n",
    "        # Variable sleep with micro-activities\n",
    "        sleep_segments = random.randint(5, 12)  # 5-12 segments\n",
    "        for segment in range(sleep_segments):\n",
    "            # Micro-activity during sleep\n",
    "            micro_work = sum(random.randint(1, 100) for _ in range(50))\n",
    "            time.sleep(random.uniform(0.5, 2.0))  # 0.5-2 second micro-sleeps\n",
    "        \n",
    "        # Log major milestones\n",
    "        if iteration_count % 100 == 0:\n",
    "            uptime = current_time - keep_alive.start_time\n",
    "            print(f\"ðŸŽ‰ MILESTONE: {iteration_count} iterations completed!\")\n",
    "            print(f\"â° Total uptime: {str(uptime).split('.')[0]}\")\n",
    "            print(f\"ðŸ”¥ Total activities: {keep_alive.stats['activities_performed']}\")\n",
    "        \n",
    "except KeyboardInterrupt:\n",
    "    print(\"ðŸ›‘ Server stopped by user\")\n",
    "    keep_alive.stop()\n",
    "except Exception as e:\n",
    "    print(f\"ðŸš¨ Server error: {e}\")\n",
    "    print(\"ðŸ”„ Error logged, continuing operation...\")\n",
    "    time.sleep(10)  # Brief pause, then continue\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
